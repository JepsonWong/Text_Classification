计算机工程
Computer Engineering
1999年　第25卷　第4期　Vol.25　No.4　1999



中英文WWW搜索引擎的信息处理
蒋澄 马范援 蒋思杰
摘要 描述了WWW搜索引擎住处处理的相关问题，尤其对中文WWW搜索引擎住处理的关键技术进行了讨论，并在此基础上提出了一个中英文WWW搜索引擎的实现方案，着重描述了其信息处理方法。
关键词 WWW 搜索引擎 索引数据库 信息检索 文档相关性
The Structure and Implementation of Chinese-English Search Engine
Jiang Cheng Ma Fanyuan Jiang Sijie
（Shanghai Jiaotong University 96033SB Shanghai 200030）
Abstract：This paper Presents some relative problems on information processing of the WWW search engine，esoecially the key technoloies on information processing of Chinese WWW search engine.A prototype of a chinese-English WWW search engine is implemented based on the Previous analysis and its information processing methods are described.
Key words:WWW;Search engine;Index database;Information retrieval;Relevance of document
　　国外已经有很多著名的搜索引擎，如AltaVista、Yahoo、InfoSeek、Lycos等，目前国内网上信息绝大部分为中文,中文检索需求很大,非常需要支持中文的搜索引擎。
1　WWW搜索引擎的结构
　　一般来讲，WWW搜索引擎可分为以下几个部分：
　　(1)WWW信息的采集　通常搜索引擎会生成多个WWW机器人(Robot)，自动地根据初始搜索列表和一定的搜索策略去WWW站点搜集文档(通常为HTML文档)。
　　(2)WWW信息的分析　对由Robot搜集的文档,一般在搜索引擎本地进行分析，提取出表达文档的关键词、摘要等信息及文档中的构成WWW结构的超链(HyperLink)。
　　(3)WWW信息的存储　把文档的分析结果按照一定结构存储在搜索引擎本地数据库服务器上，同时建立适应查询的高效的索引。
　　(4)WWW信息的检索　一般搜索引擎提供基于WWW浏览器的查询请求输入界面，它根据用户提交的查询请求 , 在本地数据库中检索出符合用户查询的记录,并通过WWW浏览器返回给用户。
2　WWW搜索引擎的信息处理
　　(1)分词技术　对中文信息的访问，不可避免地会遇到分词，这也是中文WWW搜索引擎要解决的主要问题。现有的汉语分词算法有很多，如基于词库的最大匹配法、逆向最大匹配法、最佳匹配法、高频优先分词法；基于语法和规则的分词法；基于频度和统计的分词法；基于神经网络的分词法和专家系统分词法等。这些算法适用于不同要求的场合，但又存在各自缺陷，在具体应用时可考虑几种算法相结合的方式来弥补单纯使用一种分词法所带来的不足。分词技术中的基于词库的算法目前使用较广,也较为成熟。这类算法分词的正确性很大程度上取决于所建的词库。一个词库应具备完备性和完全性两方面。词库的完备性，简单来说就是对任意一个字串，总能按词库找到对它进行切分的方法。词库的完全性，意味着词库应包含所有的词。通常先构造一个最小完备词库，然后在其基础上进行扩展，建立一个较完全词库。
　　(2)Web与数据库的集成　搜索引擎是面向WWW提供信息查询服务的，而它的数据又存储在站点的数据库服务器上，必须通过Web与数据库的集成才能实现搜索引擎强大的搜索功能。目前的Web与数据库的集成技术有CGI技术，专用的Web服务器API，以及新出现的基于Java语言的JDBC技术。传统的CGI技术是在Web服务器端编写应用程序，对数据库的查询及查询结果的生成均由此应用程序完成。相应的编程工作量大，每次运行时都独立地生成一个进程，对系统性能有较高要求。有些Web服务器厂商提供了专用的API来开发与Web服务器紧密结合在一起的后端程序，不需另外生成一个进程，程序运行效率高。不过Web服务器与后端程序处于同一进程内，一旦后端程序发生错误，整个Web服务器就要崩溃。JDBC是随着Java的日益普及，针对Java访问数据库而提出的一套支持基本SQL功能的通用低层API，易于开发独立于数据库的应用程序。
　　(3)数据的存储　搜索引擎数据库的数据存储量大，数据更新快，对查询速度要求高。搜索引擎数据库又不同于一般数据库，其数据类型相对单一，多为文本信息。数据操作简单，没有特别复杂的逻辑关系，事务处理简单。数据多集中在后台处理，前台交互少。基于上述特点，搜索引擎数据库的重点应放在一个高效快速的索引结构上。采用倒排列表与相应的Hash函数，建立一个高效快速的索引数据库，比较符合搜索引擎特有的按关键词查询的数据存储要求。
　　(4)文档相关性　一个好的搜索引擎不仅能按照用户查询要求快速准确地把结果返回给用户，而且还能去伪存真，把貌似符合查询要求，实际离用户查询要求相去甚远的信息过滤掉。进行文档相关性评价，并最终按与用户查询相关程度来筛选出查询结果是搜索引擎的重要一环。通常的文档相关性评价采用基于向量空间模型的TF*IDF算法。这种算法只考虑了文档本身内容，把文档看作是一种静态、孤立的对象来评价其相关性。但是搜索引擎作为WWW上的一个查询工具，其所处理的文档已不再是静态和孤立的。WWW本身可看作为随时间变化其结构也发生变化的动态对象。WWW实际上可描述成时间和URL 的表达式。文档中所含有的表征了文档在WWW中的结构的超链在评价文档相关性时也应作为一个评价标准。把文档放在WWW上作为其中一部分考虑时，其信息可表示成如下形式：
　　INFORMATION(Doc)=TEXTINFOMATION(Doc)+HYPERINFORMATION(Doc)
　　通常所采用的评价标准即是表达式中的TEXTIN-FORMATION，这里的HYPERINFORMATION实际上建立在TEXTINFORMATION基础之上，毕竟单纯的一个超链本身并不代表任何含义，它所指向的文档才是超链的信息源。HYPERINFORMATION隐含了TEXTINFORMATION，只有当超链被激活时(即当用户点中了文档中的URL，取回了所需的文档)，HYPERINFORMATION才真正体现出来。假如已知所有文档的TEXTINFORMATION，那么就可以给超链赋以一定的权值，求出HYPERINFORMATION。事实上当我们在浏览一篇文档时，由于不能对文档中含有的所有超链在同一时刻去激活它们，于是主观上就给它们赋了一定的权值，一般总是先激活的相应假想权值大一些。当搜索引擎进行文档相关性评价时，对文档中超链的赋值完全可以依赖TEXTINFORMATION评价作出正确的选择。
　　HYPERINFORMATION的评价可以作为TEXTIN-FORMATION评价的后续手段来精炼文档的相关性评价，这样可以灵活地对搜索引擎的效率和准确性进行控制。
3　一个中英文WWW搜索引擎的信息处理
　　基于上述分析，下面给出一个中英文搜索引擎的实现方案，具体结构参见图1。

图1　中英文搜索引擎的结构
　　(1)收集、搜索控制　通过机器人对WWW服务器的80端口发送遵循HTTP协议格式的指令申请(主要为GET、HEAD)，正常情况下能返回HTML文档或相应信息。
　　机器人在网上搜索时，常会给WWW服务器带来很大负担，同时也会因盲目地在WWW上漫游给网络带来额外负载。搜索控制模块就是控制机器人的搜索范围和搜索策略。考虑到实际运行环境(本系统主要在国内漫游)，因而对WWW服务器的域进行控制，对不同的域给以不同的权值，引导机器人有目的地访问相关站点。同时避免对同一URL的重复访问，并严格遵循Robot Exclusion标准，不去访问WWW服务器不希望机器人去访问的信息。
　　(2)文档分析　对搜集来的文档进行分析，在中文环境下首先就要解决分词。可以把基于词库的最大匹配法和基于频度与统计的无词库分词法结合起来，既保证效率，又不遗漏专有名词。同时采用正向与逆向最大匹配法，如果结果相同就认为正确，不同部分按可同时包含两部分的最小长度处理。对专有名词用基于频度与统计的分词法提取。
　　在关键词提取时充分利用标记元素。HTML文档中的题目、各级标题、粗体字、斜体字及加强的内容都用作关键词提取。为加快文档分析速度和减少数据库容量，只对有特殊标记的内容进行关键词和摘要提取，不作全文索引。同时维护一个专业词库，把在词库有的词加大它的权值，以便能更准确地反映文档的特征，词库本身可用手工和学习的方法来进行扩充。
　　(3)检索、过滤　用户提交查询请求后，由CGI程序进行参数解析并完成数据查询，再通过Web服务器把最终结果返回给用户。建立索引数据库可以考虑利用现成的数据库，或采用专门设计的数据库。
　　过滤实际上是按照相关性得分大小挑选出得分高的文档。根据上文的分析，文档相关性由两部分组成。基于向量空间模型的TF*IDF算法来计算文档的TEXTINFORMAT-ION。
 
　　其中termj是查询Q中的关键词，Otermj是termj在文档D中的出现次数，N：文档总数，n：含有termj的文档总数。
HYPERINFORMATION(D)=
　　Ehyper()是文档所含有效超链的权值函数，Nhyper()是文档所含无效超链的权值函数，所谓的有效超链即超链所指的文档被命中，而无效超链所指的文档既没有被命中同时又存在搜索引擎数据库之中。因而m+n=∑Link-∑SuspLink，公式右边前者为文档所含超链总数，后者为文档中无法取到相应文档的超链总数。TEXTINFOR()即为超链所指的文档的TEXTINFORMATION。
　　下面给出一个实例(图2)。
　　例子中列出了文档D1、D2、D3、D4、D5、D6相互引用关系及各自的TEXTINFORMATION(以数字表示)，其中W1>W2>W3>W4>W5。NW表示无效超链的权值。

图2　一个实例
　　INFORMATION(D,Q)=0.5+W1*0.7+W2*0.5+W3*0.6+W4*0.4+W5*0.2-NW
　　针对目前所谓的SEP(SEARCH ENGINE PERSUA-SION)现象(有些Web站点为了把广告页列在搜索引擎的前面，故意把文档的相关性提高)，这里可以把文档中的超链区分为指向本站点和指向外站点，对于前者就可以通过降低它的权值甚至忽略它的存在，来避免陷入Web 站点设下的"陷阱"。
4　结束语
　　本文是结合上海教育科研网的中英文WWW搜索引擎站点的建设写的。在建中的上海教育科研网搜索引擎站点主要面向国内外的教育科研，提供教研信息的检索。
作者简介：蒋澄　男，28岁，研究生，主研方向为计算机网络和数据库
作者单位：上海交通大学 96033SB 上海 200030
参考文献
　1　Berners-LeeT.Hypertext Transfer Protocol. Internet Working Draft，1993-11
　2　Berners-LeeT，Connolly D.Hypertext Markup Language.Internet Working Draft，1993-07
　3　黄昌宁，夏莹.语言信息处理专论.北京：清华大学出版社，1995
收稿日期：1998-05-27
