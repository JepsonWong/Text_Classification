自动化学报
ACTA AUTOMATICA SINICA
1997年　第23卷　第4期　Vol.23　No.4　1997



基于迭代学习的机械手操作空间
力/位置混合控制算法1）
韦庆　常文森　张彭
　　摘　要　基于对常规机械手操作空间力/位置混合控制算法的简单回顾，及对该算法所遇到困难的分析，提出了一种基于迭代学习的机械手操作空间力/位置混合控制算法，来改善机械手同高刚度环境接触时，机械手力/位置混合控制的动态控制性能.给出了学习算法的收敛条件及其证明.实验表明该算法具有快速的收敛性，能达到很高的力/位置动态控制精度.
　　关键词　迭代学习控制，力/位置混合控制，机械手操作空间控制.
HYBRID FORCE/POSITION CONTROL OF ROBOT
MANIPULATORS BASED ON ITERATIVE LEARNING
WEI QING　CHANG WENSEN ZHANG PENG
(Department of Automatic Control, National University of Defense Technology, Changsha 410073)
Abstract　By analyzing the difficulties of the conventional force/position hybrid control algorithm in applications, this paper presents a new operational space control algorithm of hybrid force/position control based on iterative learning to improve the dynamic force control performance of robot manipulators of contacting with high stiffness environment. The proof of the algorithm convergence is given. Experiments show the validity of the new algorithm. It converges rapidly and can acquire high-precision force/position dynamic control performance of robot manipulators.
Key words　 Iterative learning control, hybrid force/position control, operational space control.
1　引言
　　我们知道，机器人具备了力控制功能，可以表现出一种智能化特征，因而能够胜任更为复杂的操作任务.机器人力控制技术历经多年的研究，力/位置混合控制算法的理论框架大体建立，然而力控制技术却还没有达到实用化的程度.这同其中一个重要问题没有得到解决有很大的关系，即高刚度机械手同高刚度环境接触时，力控制的动态控制精度的提高问题.我们采用基于迭代学习的机械手操作空间力/位置混合控制算法来解决此问题.
　　迭代学习控制是1984年由Arimoto［1］等首先提出来的，他们对于线性时变系统提出了通用的学习算法. Bondi［2］1988年对于机器人控制，发展了一种迭代学习算法，利用系统的位置、速度、加速度信号来改进每次迭代的控制输入，他们通过高增益反馈将轨迹跟踪误差限制在某一上确界之内，这个上确界被用来证明他们学习控制算法的收敛性.Kuc［3］1992年对于一类非线性系统提出了一种迭代学习控制策略，在他们的算法中没有使用跟踪误差的微分项来改进前馈学习，而是通过闭环系统的高增益反馈来保证该迭代算法的收敛性.
2　机械手操作空间力/位置混合控制算法及其所遇到的困难
　　常规的机械手操作空间力/位置混合控制算法的控制力矩由两个部分组成：(1)非线性前馈项，其作用是补偿机械手重力、哥氏力以及离心力的影响.(2)通过引入一个非线性反馈矩阵，使机械手在操作空间各个方向上的控制解耦，这样可以在操作空间各个方向上设计独立的力或者位置控制器.操作空间机械手的动力学方程为
M(x)+H(x,)+G(x)=Fc+Fe
(1)
式中M(x)为机械手惯量矩阵，H(x,)为机械手哥氏力、离心力向量，G(x)为重力力矩向量，Fc为机械手操作空间控制力，Fe为环境对机械手末端执行器的作用力.把操作空间控制力Fc分为非线性前馈项Fa和非线性反馈项Fb
Fc=Fa+Fb
(2)
Fa=(x,)+(x)
(3)

(4)
式中(x,)是H(x,)的估计，(x)为G(x)的估计，(x)为M(x)的估计，S为机械手操作空间位置和姿态选择矩阵，为操作空间力和力矩选择矩阵.这里的力和位置控制器采用了普遍使用的PD控制算法，方程(1)，(2)，(3)，(4)构成机械手操作空间力/位置混合控制算法.
　　机械手在工业生产中的大多数接触作业都是同高刚度环境接触，例如对某种金属表面的加工作业，然而在同高刚度环境接触时，机械手力控制的动态控制性能不能令人满意，这就大大限制了机器人力控制技术在生产中的广泛应用，主要是由以下几方面的原因造成的：(1)上述机械手操作空间力/位置混合控制算法客观上存在动态耦合，也就是机械手既有力控制又有位置控制时，即Fe≠0时，其操作空间各个方向的控制实际上是静态解耦的，其动态控制存在维间耦合问题，这是由于M(x)矩阵的非对角特性造成的.机械手操作空间力/位置混合的动态维间耦合是影响机械手力/位置混合控制动态性能的一个主要因素.(2)机械手操作空间力/位置混合控制算法的复杂性.机械手力/位置混合控制算法的复杂性.机械手力/位置混合控制算法是个复杂的算法，完全实现各种精细的补偿和解耦需要大量的计算，这会造成系统采样控制周期过长.(3)机械手力控制未建模动力学特性.我们在文献［4］中对机械手未建模动力学特性如机械手驱动电机的动力学特性、机械手力传感器动力学特性、环境动力学特性、系统采样控制延迟等对机械手力控制稳定性的影响进行了分析，得到机械手未建模特性同机械手力控制动态稳定性密切相关，采样控制延时的减少对系统稳定性的改善有很大作用，在环境刚度很高时，PD力控制算法很难保持力控制系统稳定性，也就是高刚度机械手同高刚度环境接触时的力控制性能的提高，不能通过增大力反馈增益而达到，而只能另辟奚径了.
3　基于迭代学习的机械手操作空间力/位置混合控制算法
　　本节应用迭代学习控制，来解决机械手同高刚度环境接触时，力控制的动态性能的提高问题.我们的控制策略是采用恒定增益PD控制+前馈的学习控制，PD控制是为了保证机械手力/位置混合控制的稳定性，而机械手控制性能的提高是通过前馈项的学习而渐进得到.我们重写机械手操作空间的动力学方程为
M(x)+H(x,)+G(x)=Ub+Uf+Fe
(5)
其中Ub是线性恒定增益PD反馈控制器的输出，Uf代表前馈控制量，通过它的学习来渐进改进机械手力控制的动态控制精度.考虑第k次迭代

(6)
定义机械手的误差
ek(t)=xd(t)-xk(t)，
(7)
线性恒定增益反馈控制控制器输出为

(8)
机械手控制的前馈输出的迭代学习控制律为

(9)
式(6)，(7)，(8)，(9)构成基于迭代学习的机械手操作空间力/位置混合控制算法.该迭代学习算法的收敛性，以下将只证明机械手在操作空间全位置控制的收敛性，机械手力/位置混合控制的收敛性证明，将力反馈看成是机械手位置的高增益反馈，其收敛性证明也同上.
引理1　对于机械手的控制方程(5)，若其中M(x),H(x,)，G(x)满足Lipschitz条件，即
‖M－1(x)-M-1(y)‖≤m‖x-y‖, x,y∈S，
‖H(x,)-H(y,)‖≤h1‖x-y‖+h2‖-‖，　x,y∈S，
(10)
‖G(x)-G(y)‖＜g.‖x-y‖, x,y∈S.
其中S为机械手操作空间的可能的状态域，m,h1,h2,g为有限正常数.恒定PD控制器的输出为Ub＝KDc+KP.e，对于不同前馈输入，，系统状态满足

(11)
其中c,d为有限正常数.
定理1.机械手迭代学习控制算法(6)，(7)，(8)，(9)收敛的充分条件为
‖［I-M－1(xk)］‖≤ρ＜1.
(12)
　　证明.考虑第k和k+1次控制，有

两式分别乘以再相减，考虑到ek=xd-xk, k=d-k, k=d-k，有

将(9)式代入上式，


两边取范数，考虑到引理1有

式中　r1=‖KP‖(1+‖M-1(x)‖m)+‖M-1(x)‖m(h1+g)+m‖‖m(‖H‖m+‖G‖m+‖KD‖‖k+1‖m+‖KP‖‖ek+1‖m+‖‖m), r2=‖KD‖(1+‖M-1(x)‖m)+‖M-1(x)‖mh2,R=r1*c+r2*d, 其中定义‖f(x)‖m=(‖f(x)‖), 对于x(t)∈Rn[0,∞)，我们定义其λ范数为‖x(t)‖λ=e-λt.‖x(t)‖，上式两边乘e-λt， 取λ范数得

所以

只要‖［I－M-1(xk)］‖≤ρ＜1，我们总可以找到充分大的正数λ，使［‖［I－M-1(xk)］‖＋＜1成立，这样迭代学习误差就满足‖k＋KDk＋KPek‖λ→0，所以合理地选择控制参数KD，KP，则有‖ek‖→0，所以‖xd(t)-xk(t)‖→0，则迭代学习控制收敛，证毕.
　　说明.在定理1的证明中，我们并没有用系统的高增益反馈来保证系统迭代学习控制的收敛性，甚至没有要求系统必须稳定这一性质，没有采用高增益反馈来保证系统迭代学习的收敛性，对于机械手力控制系统来说是个优良的性质，它允许我们采用较低增益的PD控制器参数，只要保证系统最低限度的稳定性即可，系统的控制性能由迭代学习来逐渐改善，而不必采用高增益的力反馈，从而引起系统力控制的动态不稳定.上述迭代算法要采用系统加速度变量来改进系统的前馈输入，一般系统中加速度变量并不能轻易得到，要采用某种估计方法，因而会不可避免的造成信号的时间延迟，这样得到的加速度信号是不能应用于系统的实时控制的.上述迭代算法的优点是其控制过程与其前馈的学习过程实际上是两个可以分离的过程，也就是其前馈的学习过程可以离线进行，所以其加速度信号也可以离线进行处理，这样不仅可以对加速度信号进行滤波，而且可以矫正其滤波后而产生的时间延迟，从而得到满意的系统加速度信号.采取了离线式学习，所以同PD控制器相比，该算法的所需CPU处理量仅增加了一些存储时间，因此该迭代控制算法具有很好的实时性.
4　实验
　　我们所进行的基于迭代学习的机械手操作空间力/位置混合控制实验是在通用力控制系统GKD3上完成的，GKD3机械手力控制系统硬件结构由DELTA-3000工业控制机和两台PUMA-562机械手，两台六维力传感器组成.基于VME总线插板式结构的DELTA-3000工业控制机作为系统控制结构的主体，实现了两个层次的控制，即上层的组织、协调级，和底层的伺服控制级.GKD3的特色是实现了机械手操作空间六维力(力矩)/位置(姿态)的混合伺服控制.每次进行迭代学习过程前，采用常规力/位置混合控制算法，控制机械手运动到迭代学习控制的初始位置过程，然后开始该迭代学习过程，在每次控制过程中，我们仅将学习所需要的量，例如PD恒定增益控制器的输出，机械手操作空间各个方向上的速度，机械手操作空间的惯量矩阵(x)储存在内存中，在控制过程中并不处理，在每次控制过程结束后，首先对机械手操作空间各个方向的速度进行滤波，矫正时间滞后，对其进行差分得到机械手操作空间各个方向上的加速度信号，然后再按迭代学习律(9)计算下一次控制的前馈.以下为我们进行的迭代学习控制实验，(x)近似取为对角矩阵，系统控制周期为2.4ms.
　　1)机械手操作空间纯位置控制实验
　　机械手x方向位置移动为0.10m，y方向位置移动为-0.10m，z方向位置移动-0.30m.机械手运动时间为5s.机械手操作空间各个方向位置控制参数：
　　P=［500，500，500，500，500，500］；
　　D=［20，20，20，20，20，20］.
　　实验结果见图1，图中第一行序号代表迭代学习的次数.


图1(a)　x方向位置误差


图1(b)　y方向位置误差


图1(c)　z方向位置控制误差
　　2)平面跟踪实验
　　机械手xy方向为位置控制，x方向移动0.20m，y方向移动0.0m，z方向为力控制，z方向指令力为-10.0N.机械手移动时间为10s.机械手操作空间各个方向力/位控制参数为
　　P=［500,500,1,500,500,500］；
　　D=［20,20,200,20,20,20］.
　　实验结果如图2，图中第一行序号代表迭代学习的次数.


图2(a)　x方向位置控制误差


图2(b)　y方向位置控制误差


图2(c)　z方向力控制误差
　　为了比较该迭代学习控制律的控制效果，我们选取本实验第8次迭代的控制效果与常规机械手操作空间力/位混合控制算法的控制效果进行比较，如图3.常规算法的PD控制参数为
　　P=［5000,5000,1,5000,5000,5000］;
　　D=［20，20，200，20，20，20］.


图3(a)　x方向位置控制误差


图3(b)　y方向位置控制误差


图3(c)　z方向力控制误差
　　以上机械手操作空间力/位置混合控制实验表明了该算法具有快速的收敛性，能达到较高的力/位置动态和静态控制精度，同常规的机械手操作空间力/位置混合控制算法相比，该迭代学习机械操作空间力/位置混合控制算法的性能是优越的.
1)　“八六三―五一二”智能机器人主题专家组基础研究资助项目.
作者简介:韦庆　男，1969年生.1991年7月于复旦大学电子工程系获理学学士学位.1993年5月起在国防科技大学自动控制系攻读博士学位，研究方向为机械人智能控制，在攻读博士学位期间完成两个“八六三”计划项目和一个国防预研项目的研究，目前主要研究领域为机器人智能控制和机械手力控制.
作者单位:国防科技大学自动控制系　长沙　410073
参考文献
［1］　Arimoto S, Kawamura, Miyazaki F. Bettering operation of robots by learning. Journal of Robotics System, 1984,1(2):123―140.
［2］　Bondi P,Casalino G, Gambardella L.On the iter ative learning control theory for robotic manipulators. IEEE Journal on Robotics and Automation, 1988, 4(1):14―22.
［3］　Kuc T Y, Lee J S, Nam K. An iterative learning control theory for a class of nonlinear dynamic systems. Automatica, 1992, 28(6):1215―1221.
［4］　韦庆，常文森，张彭等.机械手力控制动态稳定性分析.《机器人》，1996，18(3)：173―178.
收稿日期　1995-05-29
