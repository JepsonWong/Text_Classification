信息与控制
Information and Control
1999年　第28卷　第4期　Vol.28　No.4　1999



带神经网络补偿的极点配置广义
最小方差自校正控制
靳其兵　李鸿儒　顾树生

　　摘　要： 首先用一个常规线性模型对被控对象进行辨识，再对线性模型辨识的余差用一个神 经网络进行补偿．线性模型和神经网络共同构成对象的辨识模型，并基于这一模型提出了一 种显式极点配置广义最小方差自校正控制．该方法适用于非线性对象，且具有较高精度和较 快的收敛速度，具有较强的鲁棒性． 
　　关键词： 神经网络，极点配置，广义最小方差自校正控制
　　中图分类号：TP13　　　　　　文献标识码：B

GENERALIZED POLE PLACEMENT SELF-TUNING CONTROL WITH
NEURAL NETWORK COMPENSATION
JIN Qibing1　LI Hongru2　GU Shusheng2
(1. Beijing Institute of Petrochemical Technology, Beijing　10260 0;
2. School of Information Science & Engineering,Northeastern University 11000 6)
Abstract: The Controlled plant is identified using normal lin ear model, and then the deviation identified by linear model is compensated via a neural network. The identification model is composed of a linear model and a neural network. Based on this model, an explicit generalized pole placement self -tuning control algorithm with neural network compensation is proposed. This al gorithm is suitable for nonlinear system, and has higher precision, faster conve rgent speed and stronger robustness.
Key words　neural network, pole placement, general minimum va riance self-tuning control

1　引言
　　为了能够控制非线性对象和提高自适应控制的精度和鲁棒性，近年来，提出了带神经网络补 偿的自适应控制［1～3］．[2]中提出了带神经网络补偿的预测控制，在用神经网络进行预测补偿时，要用到未来时刻的控制量输入，而未来时刻的控制量输入是未知的，通常采用的处理方法是将前一时刻的控制序列作为已知量加入．由于前一时刻所求出的控制序列不一定准确，因此，这一方法存在不足.[3]中提出了带神经网络补偿的极点配置自校正控制，但对神经网络辨识的误差一般只能达到静态补偿．本文提出了一种带神经网络补偿的极点配置广义最小方差自校正控制，该方法适用于非线性对象，且具有较高精度和较快的收敛速度，具有较强的鲁棒性．
2　对象的辨识模型
　　设对象特性可表示为：
y(k)=f[y(k-1),y(k-2),…,y(k-n),u(k-d),u(k-d-1),　　　　　　　　
…,u(k-d-m),ξ(k),ξ(k-1),…,ξ(k-nc)]　　　　　　　　　　　(1)
其中，n,m,nc为阶次，d为时间延迟，ξ(k)表示随机干扰．首先用如下常规线性模型对被控对象进行辨识
y(k)=-a1y(k-1)-a2y(k-2)-…-any(k-n)+b0u(k-d)+b1u(k-d-1)　　　　　
+…bmu(k-d-m)+ξ(k)+clξ(k-1)+…+cncξ(k-nc)　　　　　　(2)
辨识以后得到i(i=1,…,n),j(j=1,…,m),l(l=1,…,nc), 利用i、j、l就可以对k时刻的对象输出进行估计，估计值记为yL(k),则
　(3)
　　由于非线性、时变及未建模动态的影响，yL(k)和对象的实际输出y(k)将存在余差y(k)-yL(k)，这个余差可以用一个神经网络进行逼近，记神经网络的输出为yN(k), 则
yN(k)=g1[y(k-1),y(k-2),…,y(k-n),u(k-d),…,u(k-d-m)]　　　　　(4)
利用(1),将y(k-i)(i=1,2,…,d+1)依次代入(4)，并不考虑干扰的影响，得到
yN(k)=g[y(k-d),y(k-d-1),…,y(k-d-n+1),u(k-d-1),…,u(k-2d-m+1)]　　　(5)
对神经网络进行训练的目的是为了满足以下性能指标函数：
J1=min|y(k)-yL(k)-yN(k)|
从而可以得到：
y(k)=yL(k)+yN(k)+e(k)　　　　　　　　　　　　　　(6)
其中e(k)为最后的辨识误差，将(3)和(5)代入(6)，得到

即　　　　　A(z-1)y(k)=z-dB(z-1)u(k)+C(z-1)ξ(k)+yN(k)+e(k)　　　　　　　　　　(7)
　　　　　　　
　　　　　　　
　　　　　　　
　　(7)即为本文所采用的辨识模型，仿真表明，这种结构对非线性、带随机干扰的对象具有很高的精度．在[2][3]也采用了相似的结构．
　　神经网络可以采用前向神经网络，也可以采用动态递归神经网络，采用前向神经网络将具有 较多的输入个数，为了避免局部极小和提高权值的收敛速度，可以采用[4]中的权值训练方法．采用动态递归神经网络可以避免(5)中输入阶次的影响，大大减少网络的输入个数，采用[5]中提出的最优学习率进行仿真,我们得到了较好的效果．
3　带神经网络补偿的极点配置广义最小方差自校正控制
　　由于带神经网络补偿的模型结构的特殊性，就要求采用显式自适应控制，[6]提出了一种极点配置广义最小方差自校正显式控制算法，该算法能够保证全局的收敛性．为了全局的收敛性，本文就应用这一算法，并提出了带神经网络补偿的极点配置广义最小方差自校正控制．
　　设性能指标函数为
J2=E([P(z-1)y(k+d)-R(z-1w(k)+Q(z-1)u(k)]2}　　　　　　　　(8)
式中，w(k)为参考输入，P(z-1)、Q(z-1)、R(z-1)为z-1的加权多项式．
　　引入下列Diophantine方程
P(z-1)=A(z-1)E(z-1)+z-dG(z-1)　　　　　　　　　　(9)
C(z-1)E(z-1)=F(z-1)+z-dN(z-1)　　　　　　　　　　(10)
degE=d-1, degG=max(n-1,np-d), degF=d-1, degN=nc-1
E=E0+E1z-1+…+Ed-1z-(d-1)
用E乘(7)式两边并利用(9)，得(为了简化书写，以下将复杂表达式括号内的z-1忽略，如P(z-1)写成P)
Py(k+d)=Gy(k)+BEu(k)+CEξ(k+d)+Eym(k+d)+Ee(k+d)
　　再利用(10)式，得到
Py(k+d)=Gy(k)+BEu(k)+Nξ(k)+EyN(k+d)　　　　　　　　　　　
+Fξ(k+d)+Ee(k+d)　　　　　　　　　　　　　　(11)
(11)式等号右边的Fξ(k+d)、Ee(k+d)是和其余各项无关的量, 由(8)和(11)式，很容易得 到控制量u(k)由以下方程确定．
　　　　　　　　　　　　Gy(k)+BEu(k)+Nξ(k)+EyN(k+d)=Rw(k)-Qu(k)
即　　　　　　　　　　　(BE+Q)u(k)=Rw(k)-Gy(k)-Nξ(k)-EyN(k+d)　　　　　　　　　(12)
　　将(12)式的控制量方程代入(7)式，得到对象的输出方程为
　　　　(13)
　　上式中yN(k)也可以看成可测干扰． 由(13)可见，虽然引入了具有非线性特性的神经网络进行补偿, 但系统的特征多项式仍为PB+AQ，和基于线性对象设计时是一致的．并且， 令yN(k)=0、e(k)=0,就可以得到线性设计时的对象输出方程．
　　给定稳定的期望闭环极点多项式T(z-1),得到以下极点配置方程
P(z-1)B(z-1)+A(z-1)Q(z-1)=T(z-1)　　　　　　　　　　(14)
控制量u(k)由(12)决定, 但是k时刻(12)式中的yN(k+d-i)(i=0,1,…,d-1)未知．为 了求取u(k),本文采用以下处理方法．
　　由(5)式可知
yN(k+d-i)=g[y(k-i),y(k-i-1),…,y(k-n+1-i),u(k-i),u(k-i-1),
…,u(k-d-m+1-i)]
则yN(k+d-1)、yN(k+d-2)、…yN(k+1)可以由k时刻以前的输入、输出加入经过训练 的神经网络直接求得．
　　利用一阶Tayler展开，并定义
　　
　　得到
yN(k+d)=g[y(k),…,y(k-n+1),u(k),u(k-1),…,u(k-d-m+1)]　　　　　　　
≈g0+g1*[u(k)-u(k-1)]　　　　　　　　　　　　　　　(15)
在K时刻，用u(k-1)取代加入经过训练的神经网络，神经网络的输出即为g0，g1的求取 对前向神经网络可参见[7], 对动态递归神经网络可参见[8]．
　　将(15)代入(12), 得到
　　　　　　　　(16)
　　(16)即为本文控制量u(k)的实际求取方程．
　　自适应控制的步骤如下：
　　①给定期望的极点多项式T(z-1)．
　　②测取对象的输出y(k)，对(2)式的线性模型进行辨识．
　　③求yL(k)及y(k)-yL(k), 将y(k)-yL(k)作为神经网络的期望输出，对神经网络进行在线辨识．
　　④利用(14)式求P(z-1)、Q(z-1)．
　　⑤利用(9)、(10)式求E(z-1),G(z-1),N(z-1)．
　　⑥用u(k-1)代替u(k)加入经过训练的神经网络得到g0；求取g1．
　　⑦由(16)式求u(k)．
　　⑧将u(k)加入实际对象和神经网络．
　　⑨k=k+1, 转向步骤②．
4　仿真研究
　　所做的大量仿真实例都验证了本文所提出方法的正确性，下面仅以一例为证：

　　辨识模型的线性部分取为二阶对象，神经网络采用一个三层对角递归网，隐层神经元个数为10，神经网络的输入单元数为2．在\间隔内产生2000个随机数加入仿真对象，利用产生的输入、输出数据对模型进行预训练．随机干扰的最大幅值为 0.2．期望的极点多项式取为

如果利用预训练后的模型参数直接设计控制器，而不进行参数的在线校正，则由于工作点的 变化、非线性及未建模动态的影响，结果是发散的．采用极点配置广义自校正控制，而不进 行神经网络补偿，结果示于图1．采用带神经网络补偿的极点配置广义自校正控制的结果示 于图2．
　　　　　　
　　图1　极点配置广义自校正控制的结果　　　　图2　带神经网络补偿的极点配置广义自校正
　　　　　　　　　　　　　　　　　　　　　　　　　控制的结果
　　由仿真结果可以看出，本文所提出的方法是有效的，具有较快的响应速度．
5　结论
　　理论分析和仿真结果都表明了本文所提出的带神经网络补偿的极点配置广义最小方差自校正 控制方法是有效的，它比极点配置自校正控制具有更高的控制精度、更快的响应速度、更好 的鲁棒性，且适用于非线性对象．
作者简介：靳其兵,男,27岁,博士生.研究领域为神经网络及模糊控制在多变量系统中的应用.
　　　　　李鸿儒,男,30岁,博士生,讲师.研究领域为智能控制及其在多变量系统中的应用.
　　　　　顾树生,男,59岁,博士生,教授,博士生导师,东北大学信息科学与工程学院院长.研究领域为 多变量控制理论及其应用、智能控制、交流调速系统等.
作者单位：靳其兵：北京石油化工学院　102600;　
　　　　　李鸿儒、顾树生：东北大学信息科学与工程学院　沈 阳　110006
参考文献
1　罗小青,孙优贤. 基于神经元网络的前馈学习控制器. 信息与控制, 1994,23(5):311～314
2　李少远,刘浩,袁著祉. 基于神经网络误差修正的广义预测控制. 控制理论及应用, 1996, 13(5): 677～680
3　Fuli Wang, Li Mingzhong, Yang yinghua. A Neural Network-based Adaptive Pole P lacement Controller for Nonlinear System. International Tournal of Systems Scien ce, 1997,28(4):415～421
4　Robert S S, N Tepedelenliogln. A Fast New Algorithm for Training Feed Forward Neural Networks. IEEE Trans. on Signal Processing, 1992,40(1):202～2 10
5　ChaoChee K, Y L Kwang. Diagonal Recurrent Neural Networks for Dynamic Syst ems Control. IEEE trans. on Neural Networks, 1994,6(1):144～156
6　Tianyou Chai. An Indirect Stochastic Adaptive Scheme with On-Line Choice of W eighting Polynomials. IEEE Trans.on Automatic Control, 1990,35(1): 8 2～88
7　谭永红. 基于BP神经网络的自适应控制. 控制理论及应用,1994,11(1):84～ 87
8　Mingzhong Li, Fuli Wang. Adaptive Control of Black-Box Nonlinear Systems Usi ng Recurrent Neural Networks. 36th IEEE CDC, 1997,December: 10-12, California US A
收稿日期:1998-06-15
